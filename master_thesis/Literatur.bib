

@misc{DB2024,
	key					={},
	author				={{Deutsche Bahn AG}},
	title				={Automatic Train Operation (ATO)},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Online},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2022},
	URL	  				={https://digitale-schiene-deutschland.de/en/Automatic-Train-Operation},
	URLDate				={2024-01-26}
}


@ARTICLE{8859360,
  author={Wang, Yin and Wang, Lide and Hu, Yu Hen and Qiu, Ji},
  journal={IEEE Access}, 
  title={RailNet: A Segmentation Network for Railroad Detection}, 
  year={2019},
  volume={7},
  number={},
  pages={143772-143779},
  keywords={Feature extraction;Image segmentation;Visualization;Task analysis;Computer vision;Neural networks;Railroad detection;deep learning;segmentation},
  doi={10.1109/ACCESS.2019.2945633}}

@INPROCEEDINGS{7350873,
  author={Giben, Xavier and Patel, Vishal M. and Chellappa, Rama},
  booktitle={2015 IEEE International Conference on Image Processing (ICIP)}, 
  title={Material classification and semantic segmentation of railway track images with deep convolutional neural networks}, 
  year={2015},
  volume={},
  number={},
  pages={621-625},
  keywords={Concrete;Inspection;Fasteners;Rails;Electronic ballasts;Convolution;Rail transportation;Deep Convolutional Neural Networks;Railway Track Inspection;Material Classification},
  doi={10.1109/ICIP.2015.7350873}}



@INPROCEEDINGS{8517865,
  author={Le Saux, B. and Beaupère, A. and Boulch, A. and Brossard, J. and Manier, A. and Villemin, G.},
  booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Railway Detection: From Filtering to Segmentation Networks}, 
  year={2018},
  volume={},
  number={},
  pages={4819-4822},
  keywords={Rails;Rail transportation;Image segmentation;Image resolution;Buildings;Global Positioning System;Correlation;Rail detection;Railway detection;Filtering;Neural Networks},
  doi={10.1109/IGARSS.2018.8517865}}

@INPROCEEDINGS{5309526,
  author={Kaleli, Fatih and Akgul, Yusuf Sinan},
  booktitle={2009 12th International IEEE Conference on Intelligent Transportation Systems}, 
  title={Vision-based railroad track extraction using dynamic programming}, 
  year={2009},
  volume={},
  number={},
  pages={1-6},
  keywords={Dynamic programming;Cameras;Radar tracking;Machine vision;Monitoring;Radar detection;Intelligent transportation systems;Rail transportation;Computer vision;Shape},
  doi={10.1109/ITSC.2009.5309526}}

@article{qi2013efficient,
  title={Efficient railway tracks detection and turnouts recognition method using HOG features},
  author={Qi, Zhiquan and Tian, Yingjie and Shi, Yong},
  journal={Neural Computing and Applications},
  volume={23},
  pages={245--254},
  year={2013},
  publisher={Springer}
}


@INPROCEEDINGS{5940410,
  author={Nassu, Bogdan Tomoyuki and Ukai, Masato},
  booktitle={2011 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Rail extraction for driver support in railways}, 
  year={2011},
  volume={},
  number={},
  pages={83-88},
  keywords={Rails;Cameras;Pixel;Image edge detection;Feature extraction;Videos;Pattern matching},
  doi={10.1109/IVS.2011.5940410}}
  
  
  
  @INPROCEEDINGS{7952544,
  author={Purica, Andrei I. and Pesquet-Popescu, Beatrice and Dufaux, Frederic},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A railroad detection algorithm for infrastructure surveillance using enduring airborne systems}, 
  year={2017},
  volume={},
  number={},
  pages={2187-2191},
  keywords={Drones;Surveillance;Transforms;Roads;Image edge detection;Clustering algorithms;Rails;drone surveillance;enduring airborne systems;railroad detection;hough transform},
  doi={10.1109/ICASSP.2017.7952544}}


@article{teng2016visual,
  title={Visual railway detection by superpixel based intracellular decisions},
  author={Teng, Zhu and Liu, Feng and Zhang, Baopeng},
  journal={Multimedia Tools and Applications},
  volume={75},
  pages={2473--2486},
  year={2016},
  publisher={Springer}
}



@article{rs71114916,
AUTHOR = {Arastounia, Mostafa},
TITLE = {Automated Recognition of Railroad Infrastructure in Rural Areas from LIDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {11},
PAGES = {14916--14938},
URL = {https://www.mdpi.com/2072-4292/7/11/14916},
ISSN = {2072-4292},
DOI = {10.3390/rs71114916}
}

@ARTICLE{6783695,
  author={Yang, Bisheng and Fang, Lina},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Automated Extraction of 3-D Railway Tracks from Mobile Laser Scanning Point Clouds}, 
  year={2014},
  volume={7},
  number={12},
  pages={4750-4761},
  keywords={Three-dimensional displays;Rail transportation;Electronic ballasts;Roads;Feature extraction;Data mining;Intensity feature;mobile laser scanning (MLS);pattern recognition;scanning lines;track extraction},
  doi={10.1109/JSTARS.2014.2312378}}


@inproceedings{10.1145/3503161.3548050,
author = {Li, Xinpeng and Peng, Xiaojiang},
title = {Rail Detection: An Efficient Row-based Network and a New Benchmark},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548050},
doi = {10.1145/3503161.3548050},
abstract = {Rail detection, essential for railroad anomaly detection, aims to identify the railroad region in video frames. Although various studies on rail detection exist, neither an open benchmark nor a high-speed network is available in the community, making al- gorithm comparison and development difficult. Inspired by the growth of lane detection, we propose a rail database and a row- based rail detection method. In detail, we make several contribu- tions: (i) We present a real-world railway dataset, Rail-DB, with 7432 pairs of images and annotations. The images are collected from different situations in lighting, road structures, and views. The rails are labeled with polylines, and the images are catego- rized into nine scenes. The Rail-DB is expected to facilitate the improvement of rail detection algorithms. (ii) We present an ef- ficient row-based rail detection method, Rail-Net, containing a lightweight convolutional backbone and an anchor classifier. Specif- ically, we formulate the process of rail detection as a row-based selecting problem. This strategy reduces the computational cost compared to alternative segmentation methods. (iii) We evaluate the Rail-Net on Rail-DB with extensive experiments, including cross-scene settings and network backbones ranging from ResNet to Vision Transformers. Our method achieves promising perfor- mance in terms of both speed and accuracy. Notably, a lightweight version could achieve 92.77\% accuracy and 312 frames per second. The Rail-Net outperforms the traditional method by 50.65\% and the segmentation one by 5.86\%. The database and code are available at: https://github.com/Sampson-Lee/Rail-Detection.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {6455–6463},
numpages = {9},
keywords = {rail detection, neural networks, efficient classification, datasets},
location = {Lisboa, Portugal, },
series = {MM '22}
}


@misc{TuSimple,
	key					={},
	author				={{TuSimple}},
	title				={TuSimple},
	year				={2017},
	URL	  				={https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection},
	URLDate				={2024-01-26}
}

@misc{ultralytics_docs,
	key					={},
	author				={{Ultralytics Inc.}},
	title				={YOLOv8},
	year				={2023},
	URL	  				={https://docs.ultralytics.com/models/yolov8/},
	URLDate				={2024-02-03}
}

@misc{ERJU2019,
	key					={},
	author				={{Europe’s Rail Joint Undertaking}},
	title				={Innovation in the Spotlight: Towards unattended mainline train operations (ATO GoA 4)},
	year				={2019},
	URL	  				={https://rail-research.europa.eu/highlight/innovation-in-the-spotlight-towards-unattended-mainline-train-operations-ato-goa4/},
	URLDate				={2024-01-28}
}


@misc{ALSTOM2021,
	key					={},
	author				={{ALSTOM Transport SA}},
	title				={Autonomous mobility: The future of rail is automated},
	year				={2021},
	URL	  				={https://www.alstom.com/autonomous-mobility-future-rail-automated},
	URLDate				={2024-01-28}
}

@article{islam2016make,
  title={How to make modal shift from road to rail possible in the European transport market, as aspired to in the EU Transport White Paper 2011},
  author={Islam, Dewan Md Zahurul and Ricci, Stefano and Nelldal, Bo-Lennart},
  journal={European transport research review},
  volume={8},
  number={3},
  pages={1--14},
  year={2016},
  publisher={SpringerOpen}
}

@article{pagand2020fostering,
  title={Fostering the railway sector through the European Green Deal},
  author={Pagand, I and Carr, C and Doppelbauer, J},
  journal={European Union Agency For Railways},
  year={2020}
}

@misc{IEA2019,
	key					={},
	author				={{International Energy Agency}},
	title				={The Future of Rail},
	year				={2019},
	URL	  				={https://www.iea.org/reports/the-future-of-rail},
	URLDate				={2024-01-27}
}


@misc{DB2023,
	key					={},
	author				={{Deutsche Bahn AG}},
	title				={First freely available multi-sensor data set for machine learning for the development of fully automated driving: OSDaR23},
	year				={2023},
	URL	  				={https://digitale-schiene-deutschland.de/en/news/2023/OSDaR23-multi-sensor-data-set-for-machine-learning},
	URLDate				={2023-09-20}
}

@article{tagiew2023osdar23,
  title={OSDaR23: Open Sensor Data for Rail 2023},
  author={Tagiew, Rustam and K{\"o}ppel, Martin and Schwalbe, Karsten and Denzler, Patrick and Neumaier, Philipp and Klockau, Tobias and Boekhoff, Martin and Klasek, Pavel and Tilly, Roman},
  journal={arXiv preprint arXiv:2305.03001},
  year={2023}
}


@Article{cmc.2023.032757,
AUTHOR = {Jieren Cheng and Hua Li and Dengbo Li and Shuai Hua and Victor S. Sheng},
TITLE = {A Survey on Image Semantic Segmentation Using Deep Learning Techniques},
JOURNAL = {Computers, Materials \& Continua},
VOLUME = {74},
YEAR = {2023},
NUMBER = {1},
PAGES = {1941--1957},
URL = {http://www.techscience.com/cmc/v74n1/49879},
ISSN = {1546-2226},
DOI = {10.32604/cmc.2023.032757}
}



@inproceedings{pan2018SCNN,
 author = {Xingang Pan and Jianping Shi and Ping Luo and Xiaogang Wang and Xiaoou Tang},
 title = {Spatial As Deep: Spatial CNN for Traffic Scene Understanding},
 booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
 month = {February},
 year = {2018} 
}

@article{ZAIDI2022103514,
title = {A survey of modern deep learning based object detection models},
journal = {Digital Signal Processing},
volume = {126},
pages = {103514},
year = {2022},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2022.103514},
url = {https://www.sciencedirect.com/science/article/pii/S1051200422001312},
author = {Syed Sahil Abbas Zaidi and Mohammad Samar Ansari and Asra Aslam and Nadia Kanwal and Mamoona Asghar and Brian Lee},
keywords = {Object detection and recognition, Convolutional neural networks (CNN), Lightweight networks, Deep learning},
abstract = {Object Detection is the task of classification and localization of objects in an image or video. It has gained prominence in recent years due to its widespread applications. This article surveys recent developments in deep learning based object detectors. Concise overview of benchmark datasets and evaluation metrics used in detection is also provided along with some of the prominent backbone architectures used in recognition tasks. It also covers contemporary lightweight classification models used on edge devices. Lastly, we compare the performances of these architectures on multiple metrics.}
}


@INPROCEEDINGS{6340602,
  author={Fonseca Rodriguez, L. A. and Uribe, J. A. and Vargas Bonilla, J. F.},
  booktitle={2012 XVII Symposium of Image, Signal Processing, and Artificial Vision (STSIVA)}, 
  title={Obstacle detection over rails using hough transform}, 
  year={2012},
  volume={},
  number={},
  pages={317-322},
  keywords={Rails;Videos;Transforms;Image segmentation;Algorithm design and analysis;Rail transportation;Cameras;Obstacle detection;autonomous train driving;digital image processing;Hough transform},
  doi={10.1109/STSIVA.2012.6340602}}
  
  @inproceedings{yang2023lane,
  title={Lane Detection Methods Survey for Automatic Driving},
  author={Yang, Mingyue},
  booktitle={Journal of Physics: Conference Series},
  volume={2547},
  pages={012015},
  year={2023},
  organization={IOP Publishing}
}

@article{tang2021review,
  title={A review of lane detection methods based on deep learning},
  author={Tang, Jigang and Li, Songbin and Liu, Peng},
  journal={Pattern Recognition},
  volume={111},
  pages={107623},
  year={2021},
  publisher={Elsevier}
}


@Article{cryptography6020016,
AUTHOR = {Feng, Haogang and Mu, Gaoze and Zhong, Shida and Zhang, Peichang and Yuan, Tao},
TITLE = {Benchmark Analysis of YOLO Performance on Edge Intelligence Devices},
JOURNAL = {Cryptography},
VOLUME = {6},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {16},
URL = {https://www.mdpi.com/2410-387X/6/2/16},
ISSN = {2410-387X},
ABSTRACT = {In the 5G intelligent edge scenario, more and more accelerator-based single-board computers (SBCs) with low power consumption and high performance are being used as edge devices to run the inferencing part of the artificial intelligence (AI) model to deploy intelligent applications. In this paper, we investigate the inference workflow and performance of the You Only Look Once (YOLO) network, which is the most popular object detection model, in three different accelerator-based SBCs, which are NVIDIA Jetson Nano, NVIDIA Jetson Xavier NX and Raspberry Pi 4B (RPi) with Intel Neural Compute Stick2 (NCS2). Different video contents with different input resize windows are detected and benchmarked by using four different versions of the YOLO model across the above three SBCs. By comparing the inference performance of the three SBCs, the performance of RPi + NCS2 is more friendly to lightweight models. For example, the FPS of detected videos from RPi + NCS2 running YOLOv3-tiny is 7.6 times higher than that of YOLOv3. However, in terms of detection accuracy, we found that in the process of realizing edge intelligence, how to better adapt a AI model to run on RPi + NCS2 is much more complex than the process of Jetson devices. The analysis results indicate that Jetson Nano is a trade-off SBCs in terms of performance and cost; it achieves up to 15 FPSs of detected videos when running YOLOv4-tiny, and this result can be further increased by using TensorRT.},
DOI = {10.3390/cryptography6020016}
}

@article{Diwan2023,
  author    = {Tausif Diwan and G. Anirudh and Jitendra V. Tembhurne},
  title     = {Object detection using YOLO: challenges, architectural successors, datasets and applications},
  journal   = {Multimedia Tools and Applications},
  volume    = {82},
  number    = {6},
  pages     = {9243--9275},
  year      = {2023},
  month     = {03},
  day       = {01},
  issn      = {1573-7721},
  doi       = {10.1007/s11042-022-13644-y},
  url       = {https://doi.org/10.1007/s11042-022-13644-y},
  abstract  = {Object detection is one of the predominant and challenging problems in computer vision. Over the decade, with the expeditious evolution of deep learning, researchers have extensively experimented and contributed in the performance enhancement of object detection and related tasks such as object classification, localization, and segmentation using underlying deep models. Broadly, object detectors are classified into two categories viz. two stage and single stage object detectors. Two stage detectors mainly focus on selective region proposals strategy via complex architecture; however, single stage detectors focus on all the spatial region proposals for the possible detection of objects via relatively simpler architecture in one shot. Performance of any object detector is evaluated through detection accuracy and inference time. Generally, the detection accuracy of two stage detectors outperforms single stag






@article{JIANG20221066,
title = {A Review of Yolo Algorithm Developments},
journal = {Procedia Computer Science},
volume = {199},
pages = {1066-1073},
year = {2022},
note = {The 8th International Conference on Information Technology and Quantitative Management (ITQM 2020 & 2021): Developing Global Digital Economy after COVID-19},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.01.135},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922001363},
author = {Peiyuan Jiang and Daji Ergu and Fangyao Liu and Ying Cai and Bo Ma},
keywords = {Review, Yolo, Object Detection, Public Data Analysis},
abstract = {Object detection techniques are the foundation for the artificial intelligence field. This research paper gives a brief overview of the You Only Look Once (YOLO) algorithm and its subsequent advanced versions. Through the analysis, we reach many remarks and insightful results. The results show the differences and similarities among the YOLO versions and between YOLO and Convolutional Neural Networks (CNNs). The central insight is the YOLO algorithm improvement is still ongoing.This article briefly describes the development process of the YOLO algorithm, summarizes the methods of target recognition and feature selection, and provides literature support for the targeted picture news and feature extraction in the financial and other fields. Besides, this paper contributes a lot to YOLO and other object detection literature.}
}

@inproceedings{meyer2021yolino,
  title={Yolino: Generic single shot polyline detection in real time},
  author={Meyer, Annika and Skudlik, Philipp and Pauls, Jan-Hendrik and Stiller, Christoph},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2916--2925},
  year={2021}
}


@INPROCEEDINGS{5432669,
  author={Ma, Chao and Xie, Mei},
  booktitle={2010 Third International Conference on Knowledge Discovery and Data Mining}, 
  title={A Method for Lane Detection Based on Color Clustering}, 
  year={2010},
  volume={},
  number={},
  pages={200-203},
  keywords={Roads;Clustering algorithms;Least squares methods;Data mining;Space technology;Curve fitting;Vehicle safety;Intelligent vehicles;Vehicle driving;Machine vision;lane detection;color clustering;curve fitting;least square},
  doi={10.1109/WKDD.2010.118}}
  
  @article{Mittal2022,
  author    = {Mittal, Himanshu and Pandey, Avinash Chandra and Saraswat, Mukesh and Kumar, Sumit and Pal, Raju and Modwel, Garv},
  title     = {A comprehensive survey of image segmentation: clustering methods, performance parameters, and benchmark datasets},
  journal   = {Multimedia Tools and Applications},
  year      = {2022},
  volume    = {81},
  number    = {24},
  pages     = {35001--35026},
  month     = {October},
  doi       = {10.1007/s11042-021-10594-9},
  url       = {https://doi.org/10.1007/s11042-021-10594-9},
  issn      = {1573-7721},
  annotation = {Image segmentation is an essential phase of computer vision in which useful information is extracted from an image that can range from finding objects while moving across a room to detect abnormalities in a medical image. As image pixels are generally unlabelled, the commonly used approach for the same is clustering. This paper reviews various existing clustering based image segmentation methods. Two main clustering methods have been surveyed, namely hierarchical and partitional based clustering methods. As partitional clustering is computationally better, further study is done in the perspective of methods belonging to this class. Further, literature bifurcates the partitional based clustering methods into three categories, namely K-means based methods, histogram-based methods, and meta-heuristic based methods. The survey of various performance parameters for the quantitative evaluation of segmentation results is also included. Further, the publicly available benchmark datasets for image-segmentation are briefed.}
}

@article{MO2022626,
title = {Review the state-of-the-art technologies of semantic segmentation based on deep learning},
journal = {Neurocomputing},
volume = {493},
pages = {626-646},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222000054},
author = {Yujian Mo and Yan Wu and Xinneng Yang and Feilin Liu and Yujun Liao},
keywords = {Deep learning, Convolutional neural networks, Semantic segmentation, Real-time, Domain adaptation, Multi-modal fusion, Weakly-supervised},
abstract = {The goal of semantic segmentation is to segment the input image according to semantic information and predict the semantic category of each pixel from a given label set. With the gradual intellectualization of modern life, more and more applications need to infer relevant semantic information from images for subsequent processing, such as augmented reality, autonomous driving, video surveillance, etc. This paper reviews the state-of-the-art technologies of semantic segmentation based on deep learning. Because semantic segmentation requires a large number of pixel-level annotations, in order to reduce the fine-grained requirements of annotation and reduce the economic and time cost of manual annotation, this paper studies the works on weakly-supervised semantic segmentation. In order to enhance the generalization ability and robustness of the segmentation model, this paper investigates the works on domain adaptation in semantic segmentation. Many types of sensors are usually equipped in some practical applications, such as autonomous driving and medical image analysis. In order to mine the association between multi-modal data and improve the accuracy of the segmentation model, this paper investigates the works based on multi-modal data fusion semantic segmentation. The real-time performance of the model needs to be considered in practical application. This paper analyzes the key factors affecting the real-time performance of the segmentation model and investigates the works on real-time semantic segmentation. Finally, this paper summarizes the challenges and promising research directions of semantic segmentation tasks based on deep learning.}
}

@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@software{Jocher_Ultralytics_YOLO_2023,
author = {Jocher, Glenn and Chaurasia, Ayush and Qiu, Jing},
license = {AGPL-3.0},
month = jan,
title = {{Ultralytics YOLO}},
url = {https://github.com/ultralytics/ultralytics},
version = {8.0.0},
year = {2023}
}

@inproceedings{zheng2022clrnet,
  title={Clrnet: Cross layer refinement network for lane detection},
  author={Zheng, Tu and Huang, Yifei and Liu, Yang and Tang, Wenjian and Yang, Zheng and Cai, Deng and He, Xiaofei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={898--907},
  year={2022}
}
  
@inproceedings{wang2022keypoint,
  title={A keypoint-based global association network for lane detection},
  author={Wang, Jinsheng and Ma, Yinchao and Huang, Shaofei and Hui, Tianrui and Wang, Fei and Qian, Chen and Zhang, Tianzhu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1392--1401},
  year={2022}
}

@ARTICLE{4731268,
  author={Grompone von Gioi, Rafael and Jakubowicz, Jeremie and Morel, Jean-Michel and Randall, Gregory},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={LSD: A Fast Line Segment Detector with a False Detection Control}, 
  year={2010},
  volume={32},
  number={4},
  pages={722-732},
  keywords={Detectors;Image edge detection;Image segmentation;Shape;Image analysis;Testing;Feature extraction;Data mining;Information analysis;Stereo vision;Line segment detection;NFA;Helmholtz principle;a contrario detection.},
  doi={10.1109/TPAMI.2008.300}}

@article{ipol.2012.gjmr-lsd,
    title   = {{LSD: a Line Segment Detector}},
    author  = {Grompone von Gioi, Rafael and Jakubowicz, Jérémie and Morel, Jean-Michel and Randall, Gregory},
    journal = {{Image Processing On Line}},
    volume  = {2},
    pages   = {35--55},
    year    = {2012},
    note    = {\url{https://doi.org/10.5201/ipol.2012.gjmr-lsd}}
}

@INPROCEEDINGS{8100103,
  author={Almazàn, Emilio J. and Tal, Ron and Qian, Yiming and Elder, James H.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MCMLSD: A Dynamic Programming Approach to Line Segment Detection}, 
  year={2017},
  volume={},
  number={},
  pages={5854-5862},
  keywords={Image segmentation;Image edge detection;Markov processes;Probabilistic logic;Uncertainty;Training;Dynamic programming},
  doi={10.1109/CVPR.2017.620}}


@article{SAHOO1988233,
title = {A survey of thresholding techniques},
journal = {Computer Vision, Graphics, and Image Processing},
volume = {41},
number = {2},
pages = {233-260},
year = {1988},
issn = {0734-189X},
doi = {https://doi.org/10.1016/0734-189X(88)90022-9},
url = {https://www.sciencedirect.com/science/article/pii/0734189X88900229},
author = {P.K Sahoo and S Soltani and A.K.C Wong},
abstract = {In digital image processing, thresholding is a well-known technique for image segmentation. Because of its wide applicability to other areas of the digital image processing, quite a number of thresholding methods have been proposed over the years. In this paper, we present a survey of thresholding techniques and update the earlier survey work by Weszka (Comput. Vision Graphics & Image Process 7, 1978, 259–265) and Fu and Mu (Pattern Recognit. 13, 1981, 3–16). We attempt to evaluate the performance of some automatic global thresholding methods using the criterion functions such as uniformity and shape measures. The evaluation is based on some real world images.}
}


@article{10.1145/361237.361242,
author = {Duda, Richard O. and Hart, Peter E.},
title = {Use of the Hough transformation to detect lines and curves in pictures},
year = {1972},
issue_date = {Jan. 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/361237.361242},
doi = {10.1145/361237.361242},
abstract = {Hough has proposed an interesting and computationally efficient procedure for detecting lines in pictures. This paper points out that the use of angle-radius rather than slope-intercept parameters simplifies the computation further. It also shows how the method can be used for more general curve fitting, and gives alternative interpretations that explain the source of its efficiency.},
journal = {Commun. ACM},
month = {jan},
pages = {11–15},
numpages = {5},
keywords = {Hough transformation, colinear points, curve detection, line detection, pattern recognition, picture processing, point-line transformation}
}

@INPROCEEDINGS{9025646,
  author={Zendel, Oliver and Murschitz, Markus and Zeilinger, Marcel and Steininger, Daniel and Abbasi, Sara and Beleznai, Csaba},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={RailSem19: A Dataset for Semantic Rail Scene Understanding}, 
  year={2019},
  volume={},
  number={},
  pages={1221-1229},
  keywords={Rails;Semantics;Roads;Switches;Task analysis;Automobiles;Blades},
  doi={10.1109/CVPRW.2019.00161}}
  
  @article{harb2020frsign,
  title={Frsign: A large-scale traffic light dataset for autonomous trains},
  author={Harb, Jeanine and R{\'e}b{\'e}na, Nicolas and Chosidow, Rapha{\"e}l and Roblin, Gr{\'e}goire and Potarusov, Roman and Hajri, Hatem},
  journal={arXiv preprint arXiv:2002.05665},
  year={2020}
}

@ARTICLE{9050835,
  author={Toprak, Tugce and Belenlioglu, Burak and Aydın, Burak and Guzelis, Cuneyt and Selver, M. Alper},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Conditional Weighted Ensemble of Transferred Models for Camera Based Onboard Pedestrian Detection in Railway Driver Support Systems}, 
  year={2020},
  volume={69},
  number={5},
  pages={5041-5054},
  keywords={Rail transportation;Cameras;Automobiles;Videos;Detectors;Rails;Lighting;Pedestrian detection;railway transportation;transfer learning;classifier ensembles},
  doi={10.1109/TVT.2020.2983825}}

@article{CLARK200283,
title = {Infrared thermographic investigation of railway track ballast},
journal = {NDT \& E International},
volume = {35},
number = {2},
pages = {83-94},
year = {2002},
issn = {0963-8695},
doi = {https://doi.org/10.1016/S0963-8695(01)00032-9},
url = {https://www.sciencedirect.com/science/article/pii/S0963869501000329},
author = {M Clark and D.M McCann and M.C Forde},
keywords = {Ballast, Infrared, Heating, Emissivity},
abstract = {A theoretical study was undertaken to determine if infrared thermography is an appropriate method to identify the condition of railway track ballast. Within this study the optimal conditions for an infrared survey were established. A laboratory experiment was undertaken to identify clean and spent ballast using an infrared camera. By cooling the ballast and watching it heat up to room temperature over time a difference in the rate of heat transfer between the two types of ballast was observed. A field trial of the infrared camera was undertaken over an operational track as part of the work within a normal track maintenance possession. The field trial identified an area of dirty ballast within a section of clean ballast and the findings were also confirmed by using ground penetrating radar and a trial pit. The laboratory and fieldwork are described in detail and sample infrared images as well as visual images of the same area are given — along with calculated values for the emissivity. The findings proved that it is possible to calibrate an infrared camera so that it can determine the condition of the ballast. Also from the success of the field trial it was shown that infrared thermography is a suitable method of identifying the condition of ballast on an operational track}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Buch
@Book{HeSc09,
  author    = {Hesse, Stefan and Schnell, Gerhard},
  title     = {{Sensoren f{\"u}r die Prozess- und Fabrikautomation}},
  publisher = {Vieweg+Teubner},
  address   = {Wiesbaden},
  year      = {2009},
}

%Buch
@book{Ko05a,
	key					={},
	author				={Kopka, Helmut},
	title				={{LaTeX, Band 1: Einf{\"u}hrung}},
	booktitle			={},
	chapter				={},
	edition				={3},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={Pearson Studium},
	address				={{M{\"u}nchen}},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2005},
}

%eBook
@book{Ko05b,
	key					={},
	author				= {Kopka, Helmut},
	title				={{LaTeX, Band 1: Einf{\"u}hrung}},
	booktitle			={},
	chapter				={},
	edition				={3},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={eBook},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={Pearson Studium},
	address				={{M{\"u}nchen}},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2005},
	URL	  				={http://www.pearson-studium.de},
	URLDate				={2011-07-06},
}


@inproceedings{rahane2020measures,
  title={Measures of complexity for large scale image datasets},
  author={Rahane, Ameet Annasaheb and Subramanian, Anbumani},
  booktitle={2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)},
  pages={282--287},
  year={2020},
  organization={IEEE}
}

@ARTICLE{6773024,
  author={Shannon, C. E.},
  journal={The Bell System Technical Journal}, 
  title={A mathematical theory of communication}, 
  year={1948},
  volume={27},
  number={3},
  pages={379-423},
  keywords={},
  doi={10.1002/j.1538-7305.1948.tb01338.x}}

%Buch
@book{MiGo05,
	key					={},
	author				={Goossens, Michel and Mittelbach, Frank and Samarin, Alexander},
	title				={Der LaTeX Begleiter},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={Addison-Wesley Deutschland},
	address				={Bonn},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2002},
	URL	  				={},
	URLDate				={},
}

%Patentschrift
@patent{An10,
	author				={Anderson, Noel W.},
	title				={{Asymmetric stereo vision system}},
	patentnr			={EU Patent EP2296072},
	year				={2010},

}

%Projektbericht
@misc{PiMi11,
	key					={},
	author				={Piringer, Gerhard and Milovanovic, Goran and Grubmüller, Thomas},
	title				={Schweißzelle für einen Knickarmroboter},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Projektbericht},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={Wien: FH Technikum Wien, Bachelorstudiengang Mechatronik/Robotik},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2011},
	URL	  				={},
	URLDate				={},
}

%Bachelorarbeit
@misc{Ba10,
	key					={},
	author				={Baldinger, Andreas},
	title				={Improvement of NAOs speech synthesis and recognition skills},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Bachelorarbeit},	
	month				={},
	note				={},
	number				={},
	organization		={1},
	pages				={},
	publisher			={},
	address				={Wien: FH Technikum Wien, Bachelorstudiengang Mechatronik/Robotik},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2010},
	URL	  				={},
	URLDate				={},
}

%Masterarbeit
@misc{Po10,
	key					={},
	author				={Pohn, Johannes},
	title				={Condition Monitoring Systeme für die zustandorientierte Instandhaltung von Windkraftanlagen},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Diplomarbeit},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={Wien: FH Technikum Wien, Masterstudiengang Innovations- und Technologiemanagement},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2010},
	URL	  				={},
	URLDate				={},
}

%Dissertation
@misc{Hu11,
	key					={},
	author				={Humenberger, Martin},
	title				={Real-Time Stereo Matching for Embedded Systems in Robotic Applications},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Dissertation},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={Wien: Technische Universit{\"a}t Wien, Fakult{\"a}t für Elektrotechnik und Informationstechnik},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2011},
	URL	  				={},
	URLDate				={},
}

%Journalartikel
@article{HuZi10,
	key					={},
	author				={Humenberger, Martin and Zinner, Christian and Weber, Michael and Kubinger, Wilfried and Vincze, Markus},
	title				={A fast stereo matching algorithm suitable for embedded real-time systems},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={Computer Vision and Image Understanding},
	medium				={},
	month				={},
	note				={},
	number				={11},
	organization		={},
	pages				={1180-1202},
	publisher			={},
	address				={},
	school				={},
	series				={},
	type				={},
	volume				={114},
	year				={2010},
}

%eJournal-Artikel
@article{ZiKu07,
	key					={},
	author				={Zinner, Christian and Kubinger, Wilfried and Isaacs, Richard},
	title				={Pfelib: a performance primitives library for embedded vision},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={1},
	journal				={EURASIP Journal on Embedded Systems},
	medium				={eJournal},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={1-14},
	publisher			={},
	address				={},
	school				={},
	series				={},
	type				={},
	volume				={2007},
	year				={2007},
	URL	  				={http://downloads.hindawi.com/journals/es/2007/049051.pdf},
	URLDate				={2011-07-06},
}

%Konferenzbeitrag in Tagungsband
@inproceedings{HuHa07,
	key					={},
	author				={Humenberger, M. and Hartermann, D. and Kubinger, W.},
	title				={Evaluation of Stereo Matching Systems for Real World Applications Using Structured Light for Ground Truth Estimation},
	booktitle			={Proceedings of the Tenth IAPR Conference on Machine Vision Applications (MVA2007)},
	chapter				={},
	date				={2007-05-16},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	location			={Tokyo, Japan},
	medium				={},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={433-436},
	publisher			={MVA Conference Committee},
	address				={},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2007},
	URL	  				={},
	URLDate				={},
}

%Leitfaden
@misc{ANG10,
	key					={},
	author				={{Anglia Ruskin University Library}},
	title				={Guide to the Harvard Style of Referencing},
	booktitle			={},
	chapter				={},
	edition				={2},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Leitfaden},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={Cambridge, UK: Anglia Ruskin University},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2010},
	URL	  				={http://libweb.anglia.ac.uk},
	URLDate				={2011-07-06},
}

%Leitfaden
@misc{TeGo14,
	author				={Teschl, Susanne and G{\"o}schka, Karl Michael and Essl, G{\"u}nter},
	title				={{Leitfaden zur Verfassung einer Bachelorarbeit oder Master Thesis}},
	booktitle			={},
	chapter				={},
	edition				={3},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Leitfaden},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={FH Technikum Wien},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2014},
	URL	  				={www.technikum-wien.at},
	URLDate				={2014-08-04}
}

%Datenblatt
@misc{ATM11,
	key					={},
	author				={{Atmel Corporation}},
	title				={Atmel ATmega16 -- 8-bit Microcontroller with 16K Bytes In-System Programmable Flash},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Datenblatt},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={San Jose, United States: Atmel Corporation},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2011},
	URL	  				={http://www.atmel.com/dyn/resources/prod\_documents/doc2466.pdf},
	URLDate				={2011-07-06},
}

%Bild
@misc{He07,
	key					={},
	author				={Hemetsberger, H.},
	title				={AIT Stereo Sensor im Einsatz während der DARPA Urban Challenge 2007},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Fotographie},
	month				={},
	note				={AIT Austrian Institute of Technology},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2007},
	URL	  				={},
	URLDate				={},
}

%Nationaler oder internationaler Standard
@misc{ISO98,
	key					={},
	author				={{International Standards Office}},
	title				={ISO 690 -- Information and documentation: Bibliographical references: Electronic documents},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={Genf: International Standards Office},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={1998},
	URL	  				={},
	URLDate				={},
}

%Internetseite
@misc{SIE11,
	key					={},
	author				={{Siemens Automation Technology}},
	title				={SIMATIC},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={Online},
	month				={},
	note				={},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2011},
	URL	  				={http://www.automation.siemens.com/mcms/topics/de/simatic/Seiten/Default.aspx},
	URLDate				={2011-07-06},
}

@misc{SIE14,
	key					={},
	author				={{Siemens Automation Technology}},
	title				={SIMATIC},
	booktitle			={},
	chapter				={},
	edition				={},
	editor				={},
	howpublished		={},
	institution			={},
	journal				={},
	medium				={},
	month				={},
	note				={{\lbrack}Online{\rbrack} Verfügbar unter: <\url{http://www.automation.siemens.com/mcms/topics/de/simatic/Seiten/Default.aspx}> {\lbrack}Zugang am 17.10.2014{\rbrack}},
	number				={},
	organization		={},
	pages				={},
	publisher			={},
	address				={},
	school				={},
	series				={},
	type				={},
	volume				={},
	year				={2014},
	URL	  				={},
	URLDate				={}
}


